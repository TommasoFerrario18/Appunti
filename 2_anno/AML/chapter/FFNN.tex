\chapter{Feed Forward Neural Network}
\section{Introduction}
The \textbf{Feed Forward Neural Network} (FFNN) is a particular type of neural
network where each layer is connected to the next one without loop. We can think
at each layer as a vector to a vector function.

Each layer is composed by a set of neurons, where each neuron receives a set of input
from many others unit and computes its own activation rule.

We can think at a FFNN as a composition of many functions, where each function is
a layer. For example: if a FFNN try to approximate a function $f(x)$ and has $3$
hidden layer, we can represent it as:
\begin{equation*}
    f(x) = f^3(f^2(f^1(x)))
\end{equation*}
where $f^i$ is a function of $i$-layer. The overall length of hidden layers is
the \textbf{depth} of the model.

During the training process we want to learn a function $f(x)$ that, starting from
the training data, try to approximate the \textbf{target function} $f^*(x)$.

In the case of supervised problems, each instance $x$ is associated with a label
$y\sim f^*(x)$, therefore, the output layer at each point $x$ must produce a value
that is close to $y$.
\begin{note}
    It's important that is $y \sim f^*(x)$ and not $y=f^*(x)$ because we want a
    model that generalizes.
\end{note}

The behavior of the intermediate layers (\textbf{hidden layers}) are not directly
specified by the training data, but is the learning algorithm that must decide
how to use these layers to best implement an approximation of $f^*$. The dimensionality
of the hidden layers is called \textbf{width} of the model.

\subsection{Training process}
The training process can be summarized as follows: initially, the networks weights
are randomly initialized, then, for each training example $(x, y)$, the network
computes $f^*(x)$, then we compute the error $E(y, f^*(x))$ and we adjust all weights
by using the gradient approximate which is calculated with backpropagation.

\begin{note}
    During the training phase, the weights are adjusted every $n$ examples,
    where $n$ is the batch size. Weights are usually fix by considering the
    elements of a batch to avoid overfitting.
\end{note}
\section{Weight Learning}
If $f(x)$ is \textbf{non-linear} function, than we can theoretically approximate
it with an hidden layer, the problem is to find the right weights.

The essence of supervised machine learning is the creation of functions that
can look at examples (instances) and produce generalizations (predict data never seen).
This is a searching task over all possible functions, this is complex problem to
solve. So, in general, we restrict the set of all possible functions to a specific
families, this is called \textbf{hypothesis classes}.

A strategy to solve non-linear problem using a linear model is to use a
transformation of the input space. To modify the data representation, we can
apply \textbf{non-linear transformation} ($\phi$) to them. In other words, given
an instance $x$, we can think of $\phi(x)$ as a new set of features describing $x$.

There are different way to define a transformation:
\begin{itemize}
    \item Use a predefine $\phi$ called \textbf{kernel}
    \item Define manually $\phi$ but it isn't convenient.
    \item We can learn it but it isn't a general transformation. This is the
          approach used in deep learning.
\end{itemize}

In deep learning the goal is to learn a transformation $\phi$, meanwhile SVM use
a Kernel that are already defined. So, we can describe this approach using the
following model:
\begin{equation}
    f(x, \theta, \omega) = \phi(x; \theta)^T \omega
\end{equation}
where $\theta$ are the parameters used to learn the transformation $\phi$ from a
broad class of functions, while $\omega$ are the parameters that map from $\phi(x)$
to the target.

\begin{note}
    In a deep learning model $phi$ defines a hidden layer.
\end{note}

The prediction model is generally a high dimensional linear function $f(x): x \cdot W + b$,
here we have a listing:
\begin{itemize}
    \item \textbf{Sign function}: this function is used for binary classification:
          \begin{equation}
              \hat{y} = sign(f(x))
          \end{equation}
    \item \textbf{Sigmoid function}: this function is used for binary classification
          when we need a confidence on decision for log-linear binary classification.
          \begin{equation}
              \hat{y} = \frac{1}{1+e^{-f(x)}}
          \end{equation}
    \item \textbf{Softmax}: this is used for multi-class classification, suppose
          to have $k$ classes:
          \begin{equation}
              \hat{y} = softmax(f'(x)) = \frac{e^{f'(x)_i}}{\sum_{j=1}^k e^{f'(x)_j}}
          \end{equation}
\end{itemize}

\textbf{Pros} for linear models are that can be fit efficiently and reliably, because
gradient on linear model are easy to compute.

\textbf{Cons} models are restricted to linear functions so they works for data linear
separable, solved by a transformation.

\section{Kernel trick}
Transform the input space into an higher dimensional space can be useful to solve
non-linear separable problem. But, this approach increase the number of parameters
and the complexity of the model. To solve this problem we can map the input space
into a higher dimensional space using some particular functions called \textbf{kernels}.

\begin{note}
    There can be many transformations that allow the data to be linearly separated
    in higher dimensions, but not all of these functions are actually kernels.
\end{note}

This approach is functional because we can use the \textbf{kernel trick} to operate
in the original feature space without computing the coordinates of the data in a
higher dimensional space.

A general linear model would be rewritten as:
\begin{equation}
    \omega^T x + b = b+ \sum_{i=1}^m \alpha_ix^Tx^{(i)}
\end{equation}
where $b$ is the bayes, $\alpha_i$ is a coefficient, $x$ is a point, $x^(i)$ is
$i$-instance of training set and $m$ is the number of training instances.

To use this model on non-linear separable data, we need to apply a transformations $\phi$
to the input space, so the model becomes:
\begin{equation}
    f(x) = \omega^T \cdot x + b = b + \sum_{i = 1}^m \alpha_ix^Tx^{(i)} = b + \sum_{i=1}^m \alpha_i\phi (x^T) \cdot \phi(x^{(i)})
\end{equation}

The kernel trick override $\phi(x^T)\phi(x^{(i)})$ with $k(x^T, x^(i))$ without
computing $\phi(x)$ and it's more computational efficient compared to $\phi$.

Moreover kernel trick allows us to learn models that are nonlinear as a function
of $x$ using a convex optimization techniques that are guaranteed to converge
efficiently, this is possible because $\phi $ is fixed and we optimize only $\alpha_i$.
SVM uses only support vector and $\alpha_i$ regulates this, $alpha_i= 0$ if and
only if $i$ isn't a support vector.

Each algorithm that uses kernel is called \textbf{kernel machines} or \textbf{kernel
    methods}
\section{Gradient optimization}
Usually, in deep learning we want to minimize the \textbf{loss function} which in
term of operational research is the \textbf{objective function}. In order to
achieve this goal we use partial derivative to measure how the loss function changes
in correlation to a particular weights changes.

The \textbf{gradient} is a vector of all partial derivatives of the loss function
with respect to the weights.

Once we have defined that, we can use the direction opposite to the gradient to
minimize the loss function. This is called \textbf{gradient descent}.
\begin{equation}
    x' = x - \eta \nabla f(x)
\end{equation}
where $x$ is the current point, $x'$ is the next point, $\eta$ is the learning rate
and $\nabla f(x)$ is the gradient of the loss function.

The learning rete is a hyperparameter that controls how much we are moving in the
direction of the gradient. The optimal value od $\eta$ change every time we update
the weights. But, do to computational cost, we cannot compute it every time, so we
use a fixed value. The best value of $\eta$ is the one that start from a high value
in order to explore different way and reduce the chance of getting stuck in a local
minimum, and then decrease it to converge to the global minimum.

Not only the learning rate is costly to compute, but also the gradient. In fact,
the gradient is approximated using a technique called \textbf{backpropagation}.

In order to solve this optimization problem, the first step is to define the loss
function:
\begin{equation}
    J(\theta) = \frac{1}{n} \sum_{i=1}^n L(x_i; y_i; \theta)
\end{equation}
where $L$ is the loss function, $x_i$ is the input, $y_i$ is the output and $\theta$
are the parameters of the model. In addition, for reducing the risk of overfitting,
we can add a regularization term to the loss function:
\begin{equation}
    J(\theta) = \frac{1}{n} \sum_{i=1}^n L(x_i; y_i; \theta) + \lambda R(\theta)
\end{equation}
where $\lambda$ is the regularization parameter and $R(\theta)$ is the regularization
term. This is used to prevent the model from learning the noise in the training data.

\begin{note}
    A network that use small weights have better generalization properties than
    a network that use large weights.
\end{note}