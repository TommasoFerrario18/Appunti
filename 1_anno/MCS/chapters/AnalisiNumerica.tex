\chapter{Analisi Numerica}
\section{Introduzione}
In questo capitolo verranno presentate alcune tecniche per la risoluzione dei
sistemi lineari e il concetto di \textbf{numero di condizionamento}.

Lo sviluppo di un algoritmo di risoluzione di sistemi lineari deve considerare
tre fattori:
\begin{enumerate}
    \item \textbf{Memoria}: l'algoritmo deve richiedere un quantitativo ridotto
          di memoria.
    \item \textbf{Velocità}: l'algoritmo deve essere molto veloce.
    \item \textbf{Precisione}: vogliamo ottenere una soluzione più vicina possibile
          a quella reale.
\end{enumerate}
\subsection{Gestione di Matrici e Vettori}
A livello di programmazione, i vettori possono essere salvati utilizzando
aree congiunte di memoria (array). Mentre, per quanto riguarda le matrici, si
possono salvare in array secondo diverse filosofie:
\begin{itemize}
    \item \textbf{Row Major}: si salvano le righe una dopo l'altra.
          \begin{figure}[!ht]
              \centering
              \includegraphics[width=0.25\textwidth]{./img/AnalisiNumerica/RowMajor.png}
              \caption{Esempio di salvataggio di una matrice in Row Major}
          \end{figure}
    \item \textbf{Column Major}: si salvano le colonne una dopo l'altra.
          \begin{figure}[!ht]
              \centering
              \includegraphics[width=0.25\textwidth]{./img/AnalisiNumerica/ColumnMajor.png}
              \caption{Esempio di salvataggio di una matrice in Column Major}
          \end{figure}
\end{itemize}

Per salvare una matrice \textbf{sparsa} viene sempre salvata come collezione di
tuple $\langle i, \, j,\, val\rangle$. Con questa rappresentazione, anche nota
come \textbf{formato sparso}, ogni qualvolta si effettua un'operazione tra matrici
sparse si trasformano in matrici normali e si applica l'operazione.
\subsection{Gestione Errori}
L'algoritmo creato deve essere valutato in base a quanto è vicino il risultato
restituito rispetto a quello corretto. Questo deve essere fatto in quanto
i risultati sono spesso forniti come numeri floating point e quindi soggetti
a errori di approssimazione.

\begin{definizione}[\textbf{Errore assoluto}]
    Sia $\stackrel{\sim}{\textbf{x}}$ la soluzione approssimata di un sistema
    lineare $A\textbf{x} = \textbf{b}$ e sia $x$ la soluzione corretta, allora
    l'\textbf{errore assoluto} è definito come:
    \begin{equation}
        \epsilon = \|\stackrel{\sim}{\textbf{x}} - \textbf{x}\|
    \end{equation}
    dove $\|\cdot\|$ è una qualsiasi norma fra due vettori.
\end{definizione}
\begin{definizione}[\textbf{Errore relativo}]
    Sia $\stackrel{\sim}{\textbf{x}}$ la soluzione approssimata di un sistema
    lineare $A\textbf{x} = \textbf{b}$ e sia $x$ la soluzione corretta, allora
    l'\textbf{errore relativo} è definito come:
    \begin{equation}
        \epsilon = \frac{\|\stackrel{\sim}{\textbf{x}} - \textbf{x}\|}{\|\textbf{x}\|}
    \end{equation}
    dove $\|\cdot\|$ è una qualsiasi norma fra due vettori.
\end{definizione}

Il problema è conoscere la soluzione esatta del sistema per calcolare l'errore.
Un modo per ottenere la soluzione esatta possiamo inizializare un vettore $x$ in modo
randomico. In questo modo si calcola il vettore $b =A\cdot x $ e successivamente
si utilizza algoritmo di risoluzione di sistemi per risolvere il seguente
sistema $A\cdot \stackrel{\sim}{x} = b$. In questo modo $x$ è la soluzione esatta
mentre  $\stackrel{\sim}{x}$ è la soluzione approssimata. Ovviamente questa non è
la soluzione reale, ma ci interessa principalmente sapere se è risolvibile il sistema
e con che errore. Questo è determinato dalla matrice $A$ ma non dal vettore dei
termini noti $b$, per questo ci si calcola un vettore $b$ dipendente dalla soluzione
"esatta" randomica.

\begin{teorema}\label{teo:NormeEquivalenti}
    Il comportamento delle norme di vettori in $\mathbb{R}^n$ è equivalente. ossia
    preso un vettore $x\in \mathbb{R}^n$, $\exists c_1,c_2\in \mathbb{R}$ tali che:
    \begin{equation}
        c_1\|x\|_p < \|x\|_q < c_2\|x\|_p
    \end{equation}
\end{teorema}
Il teorema \ref{teo:NormeEquivalenti} ci dice che le norme a meno di alcuni
fattori moltiplicativi restituiscono gli stessi risultati.
\subsection{Velocità}
Come precedentemente detto, un aspetto importante è la velocità dell'algoritmo.
Per calcolare questo parametro dobbiamo contare il numero di operazioni che
effettuiamo, nello specifico si andrà ad utilizzare la complessità asintotica.

Analizziamo ora le velocità delle diverse operazioni:
\begin{itemize}
    \item \textbf{Prodotto Scalare}: sia $(x,y) = \sum_{i=1}^n x_iy_i$ corrisponde
          ad effettuare $n$ prodotti e $n-1$ somme, quindi si ha $n + n - 1 = 2
              n -1 \in \mathcal{O}(n)$
    \item \textbf{Norma di un vettore}: sia $\|x\| = \sqrt{\sum_{i=1}^n x_i^2}$
          corrisponde ad effettuare $n$ prodotti e $n-1$ somme, quindi si ha
          $n + n - 1 = 2n -1 \in \mathcal{O}(n)$
    \item \textbf{Prodotto Matrice-Vettore}: siano $A\in \mathbb{R}^{r\times c}$
          e $v\in \mathbb{R}^c$ allora $Av\in \mathcal{O} (rc) = \mathcal{O}(n^2)$
    \item \textbf{prodotto Matrice-Matrice}: siano $A,B\in \mathbb{R}^{n\times n}$
          allora $AB\in \mathcal{O} (n \cdot n \cdot n) = \mathcal{O} (n^3)$
    \item \textbf{Determinate}: sia $A\in \mathbb{R}^{n\times n}$ allora
          $det(A) \in \mathcal{O}(n!)$.
\end{itemize}
\section{Numero di Condizionamento}
Sappiamo che presa una matrice $A \in \mathbb{R}^{n \times n}$ e un vettore $b
    \in \mathbb{R}^n$ diverso dal vettore nullo, il sistema lineare $A \textbf{x} =
    \textbf{b}$ ammette soluzione se e soltanto se $det(A) \neq 0$.

Purtroppo quando si risolvono i sistemi lineari al calcolatore subentrano una
serie di altri fattori che influenzano il modo in cui si risolve il sistema e,
di conseguenza, la soluzione stessa. Questi fattori sono dovuti essenzialmente
alla rappresentazione dei numeri e agli errori di arrotondamento nelle operazioni.

Oltre a ciò, analizzando le velocità delle operazioni, si può notare che il
calcolo del determinante è molto complesso, quindi non è possibile utilizzarlo
per capire se un sistema è complesso da risolvere.

Per ovviare a questo problema, si introduce il concetto di \textbf{numero di
    condizionamento} calcolato su una matrice. Se tale valore è alto allora il
sistema è complesso da risolvere.
\begin{definizione}[\textbf{Numero di Condizionamento}]
    Presa una matrice $A \in \mathbb{R}^{n \times n}$, il \textbf{numero di
        condizionamento} è definito come:
    \begin{equation}
        cond(A) = \|\lambda_{max}\| \cdot \|\lambda_{min}\|
    \end{equation}
    dove $\lambda_{max}$ e $\lambda_{min}$ sono rispettivamente il massimo e il
    minimo autovalore della matrice $A$ in modulo.
\end{definizione}
Per definizione il numero di condizionamento è una quantità maggiore di $1$.
Vedremo che più questa quantità è vicino a $1$ più il sistema sarà facile da
risolvere numericamente, ossia risente meno dell'algebra di macchina. Di contro
più grande è questa quantità più il sistema sarà risolto “male”.
\begin{esempio}[Numero di Condizionamento di una Matrice di Hillbert]
    Prendiamo una matrice $H \in \mathbb{R}^{n \times n}$ definita nel seguente modo:
    \begin{equation*}
        H_{ij}=\frac{1}{1+i+j}
    \end{equation*}
    Questa matrice è nota con il nome di matrice di Hillbert ed è il classico
    esempio di matrice mal condizionata.
\end{esempio}
\section{Metodi per risolvere i sistemi}
Esistono due tipologie di metodi per la risoluzione dei sistemi lineari:
\begin{itemize}
    \item \textbf{Metodi diretti}: si effettuano delle operazioni per ottenere
          in automatico la soluzione dei sistemi.
    \item \textbf{Metodi iterativi}: sono procedure che creano una sequenza di
          vettori soluzioni che si avvicinano sempre di più alla soluzione esatta
          $\|x -\stackrel{\sim}{x}\|\rightarrow 0$ oppure si calcola $\frac{\|x
                  -\stackrel{\sim}{x}\|}{\|A\stackrel{\sim}{x} - b\|}\rightarrow 0$.
\end{itemize}

\section{Metodi diretti}
Partiamo analizzando il caso più semplice, ovvero che il sistema ammette un unica
soluzione. L'assunzione principale è che le matrici abbiano determinante diverso
da $0$.
\subsection{Sostituzione all'indietro}
Il metodo della \textbf{sostituzione all'indietro} è il metodo più efficiente per
risolvere sistemi composti da una matrice quadrata triangolare superiore.
\begin{equation}
    \begin{cases}
        u_{11}x_1 + u_{12} x_2 + \dots + u_{1n} x_n= b_1 \\
        u_{22}x_2 + u_{23} x_3 + \dots + u_{2n} x_n= b_2 \\
        \vdots                                           \\
        u_{nn}x_n = b_n                                  \\
    \end{cases} \iff \left[\begin{array}{cccc}
            u_{11} & u_{12} & \dots & u_{1n} \\
            0      & u_{22} & \dots & u_{2n} \\
            \vdots & \ddots &       & \vdots \\
            0      & \dots  &       & u_{nn}
        \end{array} \right] \cdot x = \left[\begin{array}{c}
            b_1    \\
            b_2    \\
            \vdots \\
            b_n
        \end{array}\right]
\end{equation}
A livello computazione è semplice testare se la matrice è compatibile con questo
metodo.

Una volta effettuata la verifica, il metodo coincide con il risolvere il sistema
per sostituzione.
\begin{nota}
    Bisogna stare attenti che la diagonale non contenga $0$ perché ogni volta
    si divide per un termine sulla diagonale.
\end{nota}

Sotto le ipotesi di matrice triangolare superiore possiamo calcolare facilmente
il determinante, basta calcolare il prodotto dei termini sulla diagonale, questo
ci dice che esiste una sola soluzione se il determinante è diverso da $0$
($\mathcal{O}(n)$). In aggiunta, questo ci assicura che la diagonale non contiene $0$.

La complessità dell'algoritmo sarà:
\begin{equation*}
    \#\_righe \cdot \#operazioni\_max\_riga = n \cdot (n - 1 + n - 1 + 1) = n \cdot (2n - 1) = \mathcal{O}(n^2)
\end{equation*}
\begin{nota}
    Dove il numero massimo di operazioni per riga è $n - 1$ differenze, $n - 1$
    prodotti e $1$ divisione perché nella prima riga si ha:
    \begin{equation*}
        x_1 = \frac{(b_1 - u_{12} x_2 - u_{13}x_3 - \dots - x_{1n} x_n)}{u_{11}}
    \end{equation*}
\end{nota}

Ogni singola operazione per riga si può ricavare iterativamente nel seguente modo
\begin{equation*}
    x_{n-i} = \frac{(b_i-(u_{n-i},x))}{u_{ii}}
\end{equation*}
Con $x$ inizializzato a tutti $0$ tranne la cella $n$ che sarà inizializzata a:
\begin{equation*}
    x_n = \frac{b_n}{u_{nn}}
\end{equation*}
Mentre $i$ è inizializzato a $1$, ad ogni iterazione si utilizza il vettore $x$
aggiornato nell'iterazione precedente. Al termine si ottiene una soluzione per il
sistema.
\begin{nota}
    Questo metodo può essere utilizzato anche per i sistemi lineari descritti da
    una matrice triangolare inferiore. In questo caso prima sarà necessario
    trasformare la matrice in una matrice triangolare superiore. Questo si può
    fare riordinando le righe della matrice e specchiando la matrice la colonna
    centrale. Lo stesso ragionamento si può applicare anche per matrici diagonali
    rispetto alla antidiagonale.
\end{nota}
\subsection{Trasformazioni di Gauss}
Per matrici generiche i metodi variano, si può pensare di trasformare la matrice
in una triangolare superiore equivalente, utilizzando le trasformazioni di Gauss:
\begin{itemize}
    \item \textbf{Scambiare le righe}
    \item \textbf{Sostituire una riga con una combinazione lineare di se stessa
              con un'altra}
\end{itemize}
\begin{equation}
    \begin{cases}
        a_{11}x_1 + a_{12} x_2 + \dots + a_{1n} x_n= b_1 \\
        a_{21}x_1 + a_{22} x_2 + \dots + a_{2n} x_n= b_1 \\
        \vdots                                           \\
        a_{n1}x_1 + a_{n2} x_2 + \dots + a_{nn} x_n= b_1 \\
    \end{cases}
\end{equation}