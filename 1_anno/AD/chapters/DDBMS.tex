\chapter{Basi di dati relazionali distribuite}
\begin{definizione}[\textbf{DDBMS}]
      Un \textbf{DBMS distribuito eterogeneo autonomo} è in generale una
      federazione di DBMS che collaborano per fornire accesso ai dati con livelli
      di trasparenza.
\end{definizione}
Con il termine trasparenza si intende la capacità di un sistema di
nascondere i dettagli di implementazione e di gestione dei dati, fornendo
all'utente una visione unificata e coerente del sistema.
\paragraph{Autonomia} L'autonomia fa riferimento al grado di indipendenza tra i
nodi. Possiamo distinguere diversi livelli di autonomia:
\begin{itemize}
      \item \textbf{Autonomia di progetto}: ogni nodo ha un proprio modello dei
            dati e di gestione delle transizioni.
      \item \textbf{Autonomia di condivisione}: ogni nodo sceglie la porzione di
            dati da condividere con gli altri nodi.
      \item \textbf{Autonomia di esecuzione}: ogni nodo sceglie in che modo eseguire
            le transazioni.
\end{itemize}
Partendo da questa classificazione possiamo definire diversi tipi di DBMS autonomi:
\begin{itemize}
      \item \textbf{DBMS Strettamente integrati}: in questo caso non c'è nessuna
            autonomia, i dati sono logicamente centralizzati ed esiste un unico
            data manager responsabile delle transazioni applicative. I data
            manager locali non operano in maniera autonoma.
      \item \textbf{Semi - autonomi}: ogni data manager è autonomo ma partecipa
            alle transazioni globali. Una parte dei dati è condivisa e richiedono
            modifiche architetturali per poter far parte della federazione.
      \item \textbf{Totalmente autonomi} (peer - to - peer): ogni DBMS lavora in
            completa autonomia ed è inconsapevole dell'esistenza degli altri.
\end{itemize}
\paragraph{Distribuzione} La distribuzione dei dati può avvenire in diversi
modi:
\begin{itemize}
      \item Distribuzione client - server: i dati sono distribuiti su più server
            e i client accedono ai dati attraverso le richieste fatte ai server.
            I server forniscono la gestione dei dati, mentre i client forniscono
            l'applicativo e la presentazione.
      \item Distribuzione peer - to - peer: i dati sono distribuiti su più nodi
            e ogni nodo può essere sia client che server. Ogni nodo è autonomo
            e può eseguire transazioni locali.
      \item Nessuna distribuzione: i dati sono centralizzati
\end{itemize}
\paragraph{Eterogeneità} L'eterogeneità si riferisce alla diversità dei DBMS
che compongono la federazione. Questa diversità può essere di diversi tipi:
\begin{itemize}
      \item \textbf{Linguaggio di interrogazione}: i DBMS possono utilizzare
            linguaggi di interrogazione diversi.
      \item \textbf{Modello dei dati}: i DBMS possono utilizzare modelli di dati
            diversi.
      \item \textbf{Sistema di gestione delle transazioni}: i DBMS possono utilizzare
            sistemi di gestione delle transazioni diversi.
      \item \textbf{Schema concettuale}: i DBMS possono avere schemi concettuali
            diversi.
\end{itemize}
Sviluppando una o più di queste caratteristiche possiamo quindi avere varie
tipologie di DBMS, le più importanti sono:
\begin{itemize}
      \item \textbf{DBMS Distribuiti Omogenei} (DDBMS): C'è distribuzione ma
            nessuna eterogeneità e nessuna autonomia.
      \item \textbf{DBMS Distribuito Eterogeneo}: In questa fase vederemo il
            problema dell'integrazione dei dati.
      \item \textbf{Multi Database MS}: Sistemi totalmente autonomi.
\end{itemize}
\section{DDBMS}
Vogliamo ora approfondire il concetto di \textbf{DDBMS}. Un DDBMS è un DBMS
distribuito omogeneo, ovvero un sistema in cui i dati sono distribuiti su più
nodi ma tutti i nodi utilizzano lo stesso DBMS.

Si hanno due architetture di riferimento:
\begin{itemize}
      \item Architettura dati
      \item Architettura funzionale, ovvero l'insieme di tecnologie a supporto
            dell'architettura dati
\end{itemize}

Non avendo il concetto di eterogeneità si mantiene lo stesso schema di un DBMS
centralizzato, distribuendo i dati. Questo comporta la necessità di aggiungere
uno schema logico locale tra lo schema logico e quello fisico. Non si avrà più
un solo schema logico e un unisco schema fisico, ma tanti schemi logici locali e
fisici locali (ad ogni logico corrisponde un fisico).

I vari schemi logici locali si interfacciano con uno schema logico globale,
tali schemi non sono altro che delle viste dello schema logico globale. Questa
organizzazione tra schemi logici locali e schema logico globale è la cosiddetta
organizzazione \textbf{LAV} (Local As View). In ogni caso il progettista interroga
lo schema logico globale e saranno varie tecnologie ad interrogare gli schemi
logici locali.

Per ciascuna funzione si possono avere vari tipi di gestione:
\begin{itemize}
      \item Centralizzata/gerarchica o distribuita.
      \item Con assegnazione statica o dinamica dei ruoli.
\end{itemize}
Nella fase di progettazione di un DDBMS si hanno delle differenze rispetto alla
progettazione di un DBMS centralizzato. Si hanno cinque fasi:
\begin{enumerate}
      \item Analisi dei requisiti
      \item Progettazione concettuale
      \item Progettazione della distribuzione, per capire dove mettere i dati
      \item Progettazione logica locale, che traduce dallo schema concettuale
            globale allo schema logico locale solo alcuni concetti
      \item Progettazione fisica locale
\end{enumerate}
Si introduce il concetto di \textbf{portabilità}, ovvero la capacità di eseguire
le stesse applicazioni DB su ambienti runtime diversi. Si ha anche il concetto
di \textbf{interoperabilità}, ovvero la capacità di eseguire applicazioni che
coinvolgono contemporaneamente sistemi diversi ed eterogenei. A tal fine sono
stati introdotti dei middleware, tra cui ODBC che si occupa dell'accesso a dati
di diversi vendor. ODBC, a livello architetturale, si pone sopra il DBMS e da
un'immagine indipendente da ciò che c'è sotto, trasformando tutto in una sorta
di SQL standard. Si hanno anche dei protocolli, come X-Open Distributed
Transaction Processing (DTP) che consentono di eseguire delle transazioni secondo
una logica diversa. Questo protocollo stabilisce una serie di API che vengono
implementate da ogni singolo DBMS per offrire una connettività standard.
Il protocollo funziona sia se si ha che fare con omogeneità che con eterogeneità.
Si hanno altri approcci:
\begin{itemize}
      \item \textbf{Basi dati parallele}, con incremento delle prestazione
            mediante parallelismo sia di storage devices che di processore
            (scalabilità orizzontale).
      \item \textbf{Basi dati replicate} dove si ha la replicazione della stessa
            informazione su diversi server per motivi di performance. Importanti
            per i temi della consistenza e della sicurezza
      \item \textbf{Data warehouses}, ovvero DBMS centralizzati, risultato
            dell'integrazione di fonti eterogenee, dedicati nel dettaglio alla
            gestione di dati per il supporto alle decisioni. Prevede la
            cristallizzazione dei dati, acquisiti da varie sorgenti, creando un
            nuovo schema con la memorizzazione dei dati in formato nuovo
            (solitamente relazionale). Non usa un approccio LAV.
\end{itemize}
\subsection{Architetture dei DDBMS}
Si hanno vari tipi di architetture DDBMS:
\begin{itemize}
      \item \textbf{Shared-everything}: dove il database management system e il
            disco sono in un unico nodo.
      \item \textbf{Shared-disk}: dove diversi DBMS agiscono sugli stessi dati. I
            vari DBMS accedono ai dati secondo una certa regolazione.
            Viene distribuito il carico ma si hanno problemi di concorrenza e
            hanno grandi problemi di scalabilità e costo economico
      \item \textbf{Shared-nothing}: dove ogni DBMS ha il suo disco. È molto
            scalabile e, a patto di gestire la complessità, posso aggiungere nodi
            in modo illimitato \ref{fig:sharedNothing}.
\end{itemize}
\begin{figure}[ht]
      \centering
      \includegraphics[width=0.60\textwidth]{img/SharedNothing.jpg}
      \caption{Architettura shared-nothing}
      \label{fig:sharedNothing}
\end{figure}
Vediamo quindi le proprietà generali di un DDBMS:
\begin{itemize}
      \item \textbf{Località}: i dati sono vicino alle applicazioni che li
            utilizzano più frequentemente. Questo riduce i tempi per l'esecuzione
            delle operazioni. Il paradigma è spostare i dati verso le
            applicazioni, le partizioni dei dati corrispondono spesso a delle
            partizioni naturali delle applicazioni e degli utenti. Le
            distribuzioni dei dati spesso è flessibile: è possibile spostare un
            intera tabella così come è possibile spostarne solo un sottoinsieme
            o replicarla.
      \item \textbf{Modularità} le modifiche alle applicazioni e ai dati possono
            essere effettuate a basso costo.
      \item \textbf{Resistenza ai guasti}: grazie alla replicazione dei dati
      \item \textbf{Prestazioni ed Efficienza}: distribuendo un database su più
            nodi, ogni nodo gestisce un DB di dimensioni ridotte. Questo
            significa che i singoli DB sono più facili da gestire e ottimizzare
            localmente e, in particolare, ogni nodo può adottare delle
            ottimizzazioni personalizzate. Il carico inoltre viene distribuito
            sui nodi. Tutto ciò però richiede chiaramente un coordinamento tra i
            nodi e aumenta il traffico di rete che può rivelarsi un collo di
            bottiglia per le prestazioni.
\end{itemize}
Si hanno le seguenti funzionalità specifiche:
\begin{itemize}
      \item \textbf{Trasmissione} di query, transizioni, frammenti di db e dati
            di controllo tra i nodi.
      \item \textbf{Frammentazione, replicazione e trasparenza} fattori legati
            alla natura distribuita dei dati.
      \item un query processor e un query plan per la previsione di una
            strategia globale accanto a strategie per le query locali. Si gestisce
            il passaggio tra schema logico globale e quelli locali. Chi esegue
            la query lo fa senza pensare alla frammentazione dei dati
      \item \textbf{Controllo di concorrenza} tramite algoritmi distribuiti, fondamentale
            per gli accessi in scrittura.
      \item \textbf{Strategie di recovery} e \textbf{gestione dei guasti}, sia
            in merito alla rete che all'hardware stesso.
\end{itemize}
\subsection{Frammentazione e replicazione}
\begin{definizione}[\textbf{Frammentazione}]
      Si definisce \textbf{frammentazione} come la possibilità di allocare porzioni
      diverse del database su nodi diversi.
\end{definizione}
\begin{definizione}[\textbf{Replicazione}]
      Si definisce \textbf{replicazione} come la possibilità di allocare stesse
      porzioni del database su nodi diversi.
\end{definizione}
\begin{definizione}[\textbf{Trasparenza}]
      Si definisce \textbf{trasparenza} come la possibilità per l'applicazione di
      accedere ai dati senza sapere dove sono allocati.
\end{definizione}
\subsubsection{Frammentazione}
Esistono due tipi di frammentazione:
\begin{itemize}
      \item \textbf{Frammentazione orizzontale}: si prende una tabella e la si
            frammenta in base alle righe. Si mantiene inalterato lo schema in
            quanto si ottengono solo delle tabelle più piccole. Per spezzare si
            usa una select che selezioni ogni volta un certo blocco di tabella.
      \item \textbf{Frammentazione verticale}: si prende una tabella e la si frammenta
            in base alle colonne. In ogni nuova tabella però la prima colonna
            deve essere uguale alla prima della tabella originale (ovvero dove si
            ha la chiave primaria), questo per garantire che si possa ricomporre
            la tabella originale con operazioni di join e garantire la
            trasparenza. Anche in questo caso uso una select che selezioni ogni
            volta un certo numero di colonne da mettere nella nuova tabella.
\end{itemize}
Bisogna garantire:
\begin{itemize}
      \item \textbf{Completezza}: ogni record della relazione R di partenza
            deve poter essere ritrovato in almeno uno dei frammenti
      \item \textbf{Ricostruibilità}: la relazione R di partenza deve poter essere
            ricostruita senza perdita di informazione a partire dai frammenti
      \item \textbf{Disgiunzione}: ogni record della relazione R deve essere
            rappresentato in uno solo dei frammenti
      \item \textbf{Replicazione}: l'opposto della disgiunzione
\end{itemize}
\subsubsection{Replicazione}
Si hanno diversi aspetti positivi per l'accesso in lettura, come il miglioramento
delle prestazioni in quanto consente la coesistenza di applicazioni con requisiti
operazionali diversi sugli stessi dati e aumenta la località dei dati usati da
ogni applicazioni. Nel momento in cui si ha l'accesso in scrittura si hanno però
diversi aspetti negativi. Si hanno diverse complicazioni architetturali, tra cui
la gestione della transazioni e l'update di copie multiple, che devono essere
tutte aggiornate. Inoltre bisogna studiare dal punto di vista progettuale cosa
replicare, quanto replicare, dove allocare le copie e le politiche per gestirle.

In merito all'allocazione studiamo anche gli schemi di allocazione. Ogni
frammento può essere allocato su un nodo diverso. Lo schema globale quindi
è solo virtuale e lo schema di allocazione definisce il mapping tra un frammento
e un nodo. Si ha quindi una tabella, un catalogo, che ci da informazioni sul
partizionamento, associando ogni frammento al nodo in cui è allocato.
\subsubsection{Trasparenza}
Con la trasparenza si ha la separazione della semantica di alto livello dalle
modalità di frammentazione e allocazione. Si separa quindi la logica applicativa
dalla logica dei dati ma per farlo serve uno strato software che gestisca la
traduzione dallo schema unico ai sottoschemi, comportando un aumento di
complessità del sistema e una perdita di prestazioni.
Le applicazioni (transazioni, interrogazioni) non devono essere modificate a
seguito di cambiamenti nella definizione e organizzazione dei dati e si hanno
due tipi di trasparenza, che si applicano agli schemi ANSI-SPARC nel
modello distribuito:
\begin{enumerate}
      \item \textbf{Trasparenza logica} (o indipendenza logica), ovvero
            indipendenza dell'applicazione da modifiche dello schema logico.
            Un'applicazione che usa un frammento non viene modificata se vengono
            modificati altri frammenti.
      \item \textbf{Trasparenza fisica} (o indipendenza fisica), ovvero
            indipendenza dell'applicazione da modifiche dello schema fisico
\end{enumerate}

Frammentazione e allocazione sono tra lo schema logico globale e ogni schema
logico locale. Si hanno quindi tre livelli di trasparenza:
\begin{itemize}
      \item \textbf{Trasparenza di frammentazione}, che permette di ignorare
            l'esistenza dei frammenti ed è lo scenario migliore per la
            programmazione applicativa. Il sistema si occupa di convertire query
            globali in locali e relazioni in sotto-relazioni. La scomposizione
            delle query per ogni sotto-relazione è detta query rewriting.
      \item \textbf{Trasparenza di replicazione/allocazione}, dove l'applicazione
            è consapevole dei frammenti ma non dei nodi in cui si trovano. In questo
            caso la query è già spezzata in quanto si sa di avere a che fare con un
            sistema frammentato.
      \item \textbf{Trasparenza di linguaggio}, dove l'applicazione specifica
            sia i frammenti che i nodi, nodi che possono offrire interfacce che
            non sono SQL standard. Tuttavia l'applicazione sarà scritta in SQL
            standard a prescindere dai linguaggi locali dei nodi. Le query
            vengono quindi tradotte ottimizzatone di query. Questo è il livello
            di trasparenza più basso.
\end{itemize}
\section{DBMS centralizzato}
\begin{definizione}[\textbf{DBMS}]
      Un \textbf{DBMS} (DataBase Management System) è un sistema software in grado
      di gestire collezioni di dati che siano:
      \begin{itemize}
            \item \textbf{Grandi}: di dimensioni molto maggiori rispetto alla memoria
                  centrale dei sistemi di calcolo utilizzati.
            \item \textbf{Persistenti}: i dati devono essere memorizzati su un
                  supporto di memorizzazione non volatile. Il periodo di vita dei
                  dati è indipendente dalle singole esecuzioni dei programmi che li
                  utilizzano.
            \item \textbf{Condivisi}: i dati devono essere accessibili da più utenti
                  contemporaneamente e anche da applicazioni diverse.
            \item \textbf{Affidabili}: devono essere resistenti a guasti.
      \end{itemize}
\end{definizione}
I DBMS sono solitamente posizionati tra la base di dati fisica e le applicazioni
che la utilizzano. Questo permette di separare la gestione dei dati dalla
gestione delle applicazioni, permettendo di modificare le applicazioni senza
modificare i dati e viceversa.

Le principali caratteristiche di un DBMS Centralizzato sono:
\begin{itemize}
      \item Un unico schema logico, ovvero un'unica semantica.
      \item Un'unica base di dati, ovvero un unico insieme di record interrogati
            ed aggiornati da tutti gli utenti.
      \item Nessuna forma di eterogeneità concettuale.
      \item Un unico schema fisico, ovvero un'unica rappresentazione fisica dei
            dati.
      \item Nessuna distribuzione e nessuna eterogeneità fisica.
      \item Un unico linguaggio di interrogazione, quindi un'unica modalità di
            accesso e selezione dei dati di interesse.
      \item Un unico sistema di gestione, quindi un'unica modalità di accesso,
            aggiornamento e gestione delle transazioni.
      \item Un'unica modalità di ripristino a fronte di guasti.
      \item Un unico amministratore dei dati e quindi nessuna autonomia gestionale.
\end{itemize}
Dato che le dimensioni dei dati che i DBMS devono gestire superano la capacità
della memoria centrale, le principali azioni che essi devono riguardano quindi la
memorizzazione fisica efficienti delle strutture dati nella memoria secondaria e
la scelta efficiente delle pagine da trasferire nel buffer della memoria
centrale.

Una base di dati è una risorsa integrata e condivisa fra le varie applicazioni,
questo rende necessario introdurre dei meccanismi di autorizzazione e di
controllo della concorrenza. In un mondo ideale, le transazioni sono corrette se
sono seriali, ma questo penalizzerebbe di molto l'efficienza del sistema e
quindi il controllo della concorrenza permette un ragionevole compromesso.

Quando gli utenti eseguono le query sulle basi di dati, lo fanno avendo a disposizione
lo schema logico. Questo schema però non rappresenta come sono realmente memorizzati
i dati, inoltre, le rappresentazioni logiche sono poco efficienti in memoria
secondaria. Per questo motivo, i DBMS devono tradurre le query in modo da ridurre
al minimo il numero di accessi alla memoria secondaria.

Un modo per gestire l'affidabilità delle basi di dati è quello di utilizzare
transizioni atomiche, ovvero operazioni che vengono eseguite completamente o
non vengono eseguite affatto. Questo permette di mantenere la consistenza dei
dati anche in caso di guasti.
\section{Architettura di un DBMS}
\begin{figure}
      \centering
      \includegraphics[width=0.7\textwidth]{./img/DBMS/Architettura.png}
      \caption{Architettura di un DBMS}
      \label{fig:DBMS_architecture}
\end{figure}
\subsection{Gestione degli accessi e delle interrogazioni}
Il Database administrator emette al DDL compiler i comandi del Data Description
Language riguardanti la struttura dello schema. A questo punto, il \textbf{Query
      compiler} si occupa di compilare le queries e le passa al \textbf{gestore
      delle interrogazioni} che le ottimizza e le frammenta in comandi elementari
di accesso, che invia al \textbf{gestore dei metodi di accesso}, che li trasforma
in comandi di accesso a pagine, che invia al \textbf{gestore del buffer}, il
quale è responsabile della ottimizzazione. In seguito, invia i comandi al
\textbf{gestore della memoria secondaria}, che si occupa tradurre i comandi in
accessi alle pagine sul disco.
\subsection{Gestione delle transazioni}
Il \textbf{gestore delle transazioni} si occupa di eseguire le transazioni e
garantire, attraverso delle interrogazioni al \textbf{gestore dell'affidabilità}
e il \textbf{gestore della concorrenza}, che le transazioni rispettino le
proprietà di atomicità, consistenza, isolamento e durabilità (ACID).
\section{Ottimizzazione delle interrogazioni}
La fase di ottimizzazione delle interrogazioni è suddivisa in diversi passaggi:
\begin{enumerate}
      \item Verificare che la query sia sintatticamente corretta. Per fare ciò,
            si utilizza il \textbf{Data Catalog}, che contiene le informazioni
            riguardanti la struttura dello schema.
            Questa operazione traduce la query in algebra relazionale e costruisce
            successivamente un query tree.
      \item Si trasforma un query tree in un query plan logico che viene ottimizzato
            per ridurre il suo costo. Per l'ottimizzazione si utilizza un altro
            database particolare è Statistics contenente statistiche sulla storia
            di esecuzioni precedenti delle interrogazioni.
      \item Si trasformano le espressioni scritte in algebra relazionale in
            espressioni che possono essere eseguite in modo efficiente.
      \item Si trasforma il query plan logico in un query plan fisico, ovvero
            si scelgono le operazioni di accesso ai dati e le strategie di
            esecuzione.
\end{enumerate}
\begin{definizione}[\textbf{Query Tree}]
      La query viene rappresentata come un albero nel quale:
      \begin{itemize}
            \item Le foglie corrispondono alle strutture dati logiche (tabelle).
            \item I nodi intermedi rappresentano operazioni algebriche:
                  \begin{itemize}
                        \item Selezione
                        \item Proiezione
                        \item Join
                        \item Prodotto cartesiano
                        \item Operazioni insiemistiche
                  \end{itemize}
      \end{itemize}
\end{definizione}
Chiaramente queste trasformazioni vengono eseguire mediante una strategia che
usa proprietà algebriche e una stima dei costi delle operazioni fondamentali per
i diversi metodi di accesso. In generale il problema di ottimizzazione delle
query è esponenziale, ma si utilizzano delle approssimazioni ragionevoli basate
su euristiche.
\begin{figure}
      \centering
      \includegraphics[width=0.7\textwidth]{./img/DBMS/Ottimizzazione_query.png}
      \caption{Ottimizzazione delle interrogazioni}
      \label{fig:Query_Optimization}
\end{figure}
\section{Gestione delle transazioni}
Le transazioni sono degli insiemi di istruzioni di lettura e scrittura sulla base
di dati che godono di alcune proprietà che permettono la loro corretta esecuzioni
in ambienti concorrenti e non affidabili.

Generalmente vengono identificate da un inizio begin - transaction e una fine
end - transaction e al cui interno deve essere eseguito una e una sola
volta uno dei seguenti comandi:
\begin{itemize}
      \item \textbf{commit work} per terminare correttamente
      \item \textbf{rollback work} per abortire la transazione
\end{itemize}

Un \textbf{sistema transazionale} (OLTP) è in grado di definire ed eseguire
transazioni per un certo numero di applicazioni concorrenti.

Le transazioni godono delle proprietà ACID:
\begin{itemize}
      \item \textbf{Atomicità}: una transazione è un'unità indivisibile di
            esecuzione che deve essere eseguita completamente o non deve essere
            eseguita affatto.
      \item \textbf{Consistenza}: una transazione deve portare il database da uno
            stato consistente ad un altro stato consistente.
      \item \textbf{Isolamento}: le transazioni devono essere eseguite in modo
            indipendente l'una dall'altra.
      \item \textbf{Durabilità}: una transazione che ha terminato con successo
            deve essere persistente anche in caso di guasti.
\end{itemize}
Se queste proprietà non sono rispettate si possono verificare delle anomalie,
come:
\begin{itemize}
      \item \textbf{Perdita di aggiornamenti}: due transazioni leggono lo stesso
            dato, lo modificano e lo scrivono, ma solo una delle due modifiche
            viene mantenuta.
      \item \textbf{Lettura sporca}: una transazione legge un dato che è stato
            modificato da un'altra transazione e non ancora committato.
      \item \textbf{Non ripetibilità della lettura}: una transazione legge due
            volte lo stesso dato e ottiene due valori diversi.
      \item \textbf{Fantom reads}: una transazione legge due volte lo stesso
            insieme di dati e ottiene due insiemi diversi.
\end{itemize}
\subsection{Gestione della concorrenza}
La gestione della concorrenza è necessaria per garantire l'isolamento delle
transazioni. Questo è necessario perché le transazioni possono essere eseguite
in modo concorrente e quindi possono accedere contemporaneamente agli stessi
dati.
\begin{definizione}[\textbf{Schedule}]
      Una sequenza di esecuzione di un insieme di transizioni è detta \textbf{schedule}.
      Esso si dice \textbf{seriale} se una transazione è eseguita per intero prima
      che un'altra inizi.
\end{definizione}
Si sfrutta quindi la proprietà di isolamento facendo in modo che ogni
transazione esegua come se non ci fosse concorrenza.

Si ha quindi che uno schedule è serializzabile se l'esito della sua esecuzione è
lo stesso che si avrebbe con una qualsiasi sequenza seriale delle transazioni
contenute.

Si hanno quindi diversi algoritmi per il controllo della concorrenza secondo
varie tipologie:
\begin{itemize}
      \item \textbf{Controllo basato su conflict equivalence}
      \item \textbf{Controllo di concorrenza basato su locks} (protocollo 2PL o two
            phase locking, shared locks e gestione dei deadlock). Il protocollo
            2PL è usato nei DBMS dove per costruzione si hanno schedule
            serializzabili usando i lock per bloccare l'accesso alla risorse da
            parte di una transazione fino a che una risorsa non sia rilasciata.
            Si hanno quindi i concetti di lock e unlock che garantiscono l'uso
            esclusivo di una risorsa e l'autorizzazione esclusiva dell'uso di una
            risorsa viene dato dal gestore delle transazioni. Si hanno delle
            tabelle di lock. Si ha che, in ogni transazione, tutte le richieste
            di lock precedono tutti gli unlock.
      \item controllo di concorrenza basato su timestamps
\end{itemize}

\section{DBMS distribuito}
Esistono diverse architetture di DBMS distribuiti alcune delle quali sono
riportate in figura \ref{fig:DBMS_distributed_architecture}.
\begin{figure}
      \centering
      \includegraphics[width=0.7\textwidth]{./img/DBMS/DBMS_distributed_architecture.png}
      \caption{Architetture di DBMS distribuiti}
      \label{fig:DBMS_distributed_architecture}
\end{figure}
\section{Query nei DBMS distribuiti}
Nel capitolo precedente abbiamo visto come le query vengono ottimizzate in un
DBMS centralizzato. In un DBMS distribuito, invece, le query vengono ottimizzate
in modo diverso. In particolare, si hanno le seguenti fasi:
\begin{itemize}
      \item \textbf{Query decomposition}: la query viene decomposta in
            sottoquery che possono essere eseguite in modo indipendente. Questa
            fase tiene conto dello schema logico globale e non considera la
            distribuzione dei dati. Usa delle tecniche di ottimizzazione algebrica
            come quelle usate nei DBMS centralizzati.
            In output a questa fase si ha un query tree globale, che non tiene
            conto dei costi di comunicazione.
      \item \textbf{Data Location}: in questa fase si considera la distribuzione
            dei frammenti. Si ottimizzano le operazioni rispetto alla
            frammentazione utilizzando tecniche di riduzione. In output si ha una
            query efficiente sui frammenti ma non ottimizzata.
      \item \textbf{Global optimization}: in questa fase si ottimizza la query
            rispetto ai costi di comunicazione, aggiungendo agli operatori
            algebrici quelli per la comunicazione. L'obiettivo è quello di
            trovare il piano di esecuzione che minimizza il costo totale. Le
            decisioni più importanti riguardano le operazioni di join perché
            non si possono trasferire gli indici e quindi è l'operazione più lenta.
      \item \textbf{Local optimization}: in questa fase si ottimizza il piano di
            esecuzione per ogni singolo nodo.
\end{itemize}
Gli obiettivi dell'ottimizzazione sono ridurre il costo totale, ovvero la somma
dei costi di operazioni locali come input e output, e il costo di comunicazione.
Oltre a ciò, si vuole ridurre il response time, ovvero la somma dei costi tenendo
conto del parallelismo.

Nei database distribuiti il costo è dato dalla seguente formula:
\begin{equation*}
      \text{Costo comunicazione} = \text{C\_{MSG}} \cdot \#\ msgs  + \text{C\_{TR}} \cdot \#bytes
\end{equation*}
dove:
\begin{itemize}
      \item \textbf{$C\_{MSG}$} è il costo di trasmissione di un messaggio
      \item \textbf{$C_{TR}$} è il costo di trasmissione di un byte
      \item \textbf{$\#\ msgs$} è il numero di messaggi
      \item \textbf{$\#bytes$} è il numero di byte
\end{itemize}
Nel tempo di risposta, a differenza del costo di trasmissione, i costi delle
operazioni in parallelo non si sommano, ottenendo la seguente formula:
\begin{equation*}
      \text{Tempo di risposta} = C\_{MSG} \cdot seq\_\#msgs + C_{TR} \cdot seq\_\#bytes
\end{equation*}
dove $seq\_\#msgs$ è il massimo numero di messaggi che devono essere comunicati
in modo sequenziale.

Naturalmente, il costo più importante deve essere valutato in base a alla
situazione in cui mi trovo. Chiaramente se si lavora in una grande rete
geografica, il costo di comunicazione sarà molto più alto rispetto al costo di
esecuzione locale. Viceversa nelle reti locali, il costo di comunicazione sarà
molto più basso rispetto al costo di esecuzione locale.

Possiamo essere interessati a:
\begin{itemize}
      \item Minimizzazione tempo di risposta: più parallelismo può portare ad
            aumento del costo totale (maggiore numero di trasmissioni e
            processing locale)
      \item Minimizzazione costo totale: somma dei costi senza tener conto del
            parallelismo: utilizza meglio le risorse e aumento del throughput (con
            peggioramento del response time in generale)
\end{itemize}
\subsection{Operazione di join}
Dato che nei quando si trasferiscono i dati non è possibile passare gli indici,
le operazioni di join sono quelle più costose dal punto di vista computazionale.
Per questo motivo, l'operazione di \textbf{semijoin} può essere in alcune circostanze
un'alternativa più efficiente rispetto al join.
\begin{definizione}[\textbf{Semijoin}]
      Dati due insiemi $R$ e $S$, il semijoin di $R$ e $S$ è definito come:
      \begin{equation*}
            R \text{semijoin}_A S \equiv \pi_{R^\ast}(R \, \text{join}_A \, S)
      \end{equation*}
      dove $R^\ast$ è l'insieme delle colonne di $R$. Il semijoin è la proiezione
      sugli attributi di $R$ del join di $R$ e $S$.
\end{definizione}
\begin{nota}
      Il semijoin non è commutativo.
\end{nota}
Chiaramente l'uso del semi - join è conveniente se il costo del suo calcolo e
del trasferimento del risultato sono inferiori al costo di trasferimento
dell'intera relazione del costo del join intero.

In generale, l'uso del semijoin è più conveniente se il costo del suo calcolo e
del trasferimento del risultato è inferiore al consto del trasferimento
dell'intera relazione e del costo del join intero.
\section{Controllo della concorrenza}
Fino a questo momento abbiamo considerato le interrogazioni più semplici. Vogliamo
ora analizzare la gestione delle scritture sui database distribuiti. In particolare,
possiamo classificare le transazioni in due categorie:
\begin{itemize}
      \item \textbf{Dirette a un unico server remoto}: in questo caso il controllo
            della concorrenza è simile a quello dei DBMS centralizzati. Dobbiamo
            distinguere tra due tipi di transazioni:
            \begin{itemize}
                  \item \textbf{Remote request}: ovvero operazioni di sola lettura
                  \item \textbf{Remote transaction}: ovvero operazioni di lettura e scrittura.
            \end{itemize}
      \item \textbf{Dirette a un numero arbitrario di server}: in questo caso il
            controllo della concorrenza è più complesso. In questo caso la
            classificazione si divide in:
            \begin{itemize}
                  \item \textbf{Distributed requests}: operazioni read - only
                        arbitrarie nelle quali ogni singola operazione SQL si può riferire
                        a qualunque insieme dei server. Richiede un ottimizzatore distribuito.
                  \item \textbf{Distributed transactions}: numero arbitrario di
                        operazioni SQL, ogni operazione è diretta ad un unico server.
                        Le transazione possono modificare più di un database. Richiede
                        un protocollo transazionale di coordinamento distribuito (two
                        - phase commit).
            \end{itemize}
\end{itemize}

La distribuzione non ha conseguenze su consistenza e durabilità in quanto la
consistenza non dipende dalla distribuzione poiché i vincoli descrivono solo
proprietà logiche dello schema. Mentre, la durabilità è garantita localmente da
ogni sistema.

È invece necessario rivedere alcuni componenti dell'architettura in merito a
\textit{isolamento} tramite concurrency control e ad \textit{atomicità} tramite
reliability control e recovery manager.
\subsection{Concurrency control}
L'idea alla base del controllo della concorrenza è che ogni transizione $t_i$
possa essere suddivisa in $t_{ij}$ transazioni che saranno eseguite sul nodo $j$.
Ogni sotto-transazione viene schedulata in modo indipendente dai server di
ciascun nodo. La schedule globale dipende quindi dalle schedules locali su ogni nodo.

In questo modo lo schedule globale andrà a dipendere dallo schedule locale di
ciascun nodo. Inoltre in questo caso, seppur localmente le transazioni sembrino
serializzabili, si crea la possibilità di avere conflitto a livello globale.
\subsection{ROWA}
Nel caso di database non è replicato e ogni schedule locale è serializzabile 
allora lo schedule globale è serializzabile se gli ordini di serializzazione 
sono gli stessi per tutti i nodi, ovvero se il flusso delle transazioni è lo
stesso per tutti i nodi.

Quando si aggiunge la replicazione dei dati le cose cambiano. Nello specifico 
possiamo violare la mutua consistenza dei database locali per la quale tutte le 
copie devono avere lo stesso valore al termine della transazione. Abbiamo quindi 
bisogno di un protocollo di controllo delle repliche.

Un protocollo è il \textbf{ROWA} (\textbf{Read Once Write All}). Questo 
protocollo mappa le operazioni di lettura su una qualunque delle copie, mentre 
le operazioni di scrittura vengono mappate su tutte le copie. Di fatto, finché 
non sono accertate tutte le write su tutte le copie, la transazione non continua. 

Questo protocollo garantisce la consistenza dei dati ma a scapito chiaramente delle
performance. Questa condizione può essere rilassata con dei protocolli asincroni 
più efficienti.

Nel distribuito il 2PL  non funziona pià