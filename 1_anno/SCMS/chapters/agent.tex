\chapter{Agenti}
\section{Introduzione}
Nell'Intelligenza artificiale si è passati da Classical AI verso la Distribuited
AI.
\begin{definizione}[\textbf{Intelligent Agent}]
    Si definisce \textbf{Intelligent Agent} come lo studio degli agenti che
    ricevono delle percezioni dall'ambiente ed effettuano delle azioni su di esso.
\end{definizione}
Possiamo definire l'intelligenza artificiale attraverso lo studio di agenti,
stiamo \textbf{Agentification of AI}.
\begin{definizione}[\textbf{Agentification AI}, \textbf{Classical AI}]
    Con il termine \textbf{Agentification AI} ci riferiamo a una situazione in
    cui un singolo agente risolve problemi adottando diverse tecniche e approcci.
\end{definizione}
\section{Agente}
Il termine \textbf{agente} viene definito in diversi modi da diversi autori,
vogliamo ora riportare alcune definizioni di agente:
\begin{definizione}[Russel e Norvig]
    Un \textbf{agente} è qualcosa che percepisce l'ambiente attraverso sensori e
    agisce su di esso attraverso attuatori.
\end{definizione}
\begin{esempio}[Esempio di agente]
    Un esempio sono gli agenti umani composti da sensori come occhi, orecchie e
    altri organi, mentre è composto da attuatori che sono mani, gambe, bocca e
    parti del corpo.

    Un ulteriore esempio possono avere agenti robotici composti dai rispettivi
    sensori e attuatori.
\end{esempio}

Di un agente possiamo definire la \textbf{funzione agente} che mappa la storia
delle percezioni in una azione, ovvero:
\begin{equation}
    f: P^* \rightarrow A
\end{equation}
dove $P^*$ è l'insieme delle parti delle sequenze di percezioni e $A$ è l'insieme
delle azioni. Questa funzione può essere rappresentata in diversi modi:
\begin{itemize}
    \item \textbf{Production system}
    \item \textbf{Reactive agents}
    \item \textbf{Real-time conditional planners}
    \item \textbf{Neural network}
    \item \textbf{Decision-theorem system}
\end{itemize}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.5\textwidth]{./img/Agenti/AgenteEAmbiente.png}
    \caption{Schema di un agente}
    \label{fig:agenti}
\end{figure}

L'agente sarà anche formato dal \textbf{programma} dell'agente che viene
eseguito sulla sua \textbf{architettura} fisica per svolgere la funzione agente.
\begin{center}
    Agent = Program + Architecture
\end{center}
\begin{definizione} [\textbf{Distribuited AI}]
    La \textbf{Distribuited AI} consiste in un sistema di entità le quali possono
    risolvere un problema effettuando delle azioni e interagendo con l'ambiente,
    sia in collaborazione, sia in competizione.
\end{definizione}
A differenza della Classical AI in cui si ha un solo agente, nella Distribuited AI
si ha un sistema di agenti.
\begin{definizione} [\textbf{Sistema}]
    Un \textbf{sistema} è un gruppo di elementi che formano un insieme che
    collabora per raggiungere un obiettivo comune. Questo ci dice che un sistema
    è qualcosa in più di un singolo insieme di elementi, in quanto è presente un
    organizzazione tra le parti che lo compongono.
\end{definizione}
Prima abbiamo accennato a un sistema di entità che collaborano per risolvere un
problema, questo sistema può essere distribuito. Vogliamo ora capire cosa
può essere distribuito:
\begin{itemize}
    \item \textbf{Distribuited solving of problem}: la soluzione di un problema
          è distribuita, ovvero la soluzione del problema richiede capacità che
          appartengono a più entità.
    \item \textbf{Solving of distribuited problem}: distribuzione a livello di
          dominio del problema. In questo caso si può adottare una soluzione
          centralizzata. Un esempio di questa casistica è data dal coordinamento
          di robot in un magazzino.
    \item \textbf{Distribuited techniques for problem solving}: distribuzione a
          livello di tecniche da utilizzare per la risoluzione del problema.
\end{itemize}
\begin{esempio}[Distribuited solving of problem]
    Un esempio di problema non distribuito che viene risolto in modo distribuito
    è il riconoscimento del parlato. In questo caso si ha un sistema di agenti
    che collaborano per risolvere il problema. Sono presenti diversi livelli
    gerarchici, ogni livello si occupa di un particolare task.
\end{esempio}
\begin{esempio}[Solving of distribuited problem]
    Un esempio di problema distribuito che viene risolto in modo centralizzato è
    legato alla gestione di un magazzino. In questo caso si ha un sistema centrale
    che riceve le informazioni degli attuatori (robot) e comunica agli attuatori le
    azioni da svolgere. I vantaggi dell'approccio centralizzato sono la
    configurabilità e la predicibilità, quindi posso dimostrare proprietà. Posso
    predire malfunzionamenti degli agenti, quindi posso sovradimensionare la
    struttura per gestire i probabili malfunzionamenti. Si ha quindi una scalabilità,
    flessibilità e adattabilità limitata.

    Una soluzione alternativa è quella di convertire il sistema trasformando i
    muletti da attuatori ad agenti i quali comunicano col sistema centrale per
    effettuare i task. Passando quindi da un paradigma:
    \begin{center}
        muletto x porta al posto y un prodotto z
    \end{center},
    a uno del tipo:
    \begin{center}
        chi si offre di portare al posto y il prodotto z?
    \end{center}
    A questo punto i muletti risponderanno e il sistema selezionerà il migliore.
    Aumenta la complessità degli agenti perché devono gestire le richieste centrali
    e inoltre deve comunicare con gli altri agenti per non scontrarsi negli
    incroci. Quindi gli agenti devono avere una rappresentazione dell'ambiente,
    cosa che non avevano nella soluzione centralizzata, perché questo veniva
    gestito tutto dal server centrale.
\end{esempio}
\begin{esempio}[Distribuited techniques for problem solving]
    Un esempio sono i nemici di un videogioco che cooperano che sconfiggere il
    giocatore. Rappresento e gestisco i bot come agenti.
\end{esempio}

Nel passato per implementare la distribuited AI si avevano diversi metodi:
\begin{itemize}
    \item \textbf{Memoria distribuita}: struttura dati condivisa con problemi
          sull'accesso concorrente e con strategie di controllo degli agenti.
          Implementato con Linda che suggerisce un nuovo modo per gestire la
          concorrenza.
    \item \textbf{Processing autonomo} concorrente e il coordinamento tra gli
          agenti con scambio di messaggi. Implementato con modello ad Attori.
\end{itemize}
Attualmente, si utilizzano delle metodologie basate su middleware per sistemi
distribuiti ad esempio attraverso code o meccanismi di publish and subscribe
etc$\dots$ Degli esempi di tecnologie che implementano questi meccanismi sono
Redis e Kafka.

Gli approcci basati su sistemi di agenti presentano diverse criticità:
\begin{itemize}
    \item Il sistema viene modellato definendo l'ambiente, l'architettura e poi
          si ragiona sul singolo agente. Non per tutti i sistemi si può ragionare
          sul singolo agente. Spesso esistono azioni eseguite dagli agenti che
          vanno a influenzare l'ambiente.
    \item La modifica sull'ambiente può limitare la scelta delle azioni degli
          agenti quindi l'autonomia spesso non è buona e complica la gestione
          degli agenti.
\end{itemize}
\section{Architettura degli agenti}
Una prima classificazione degli agenti è quella di Genesereth la quale si basa
sul fatto che gli agenti possono essere classificati in base alle loro capacità
interne e alle risorse a loro disposizione. Questa prima classificazione
distingue gli agenti in:
\begin{itemize}
    \item \textbf{Tropistic}
    \item \textbf{Hysteretic}
    \item \textbf{Knowledgw-based}
\end{itemize}
\begin{nota}
    Questa analisi è stata effettuata considerando un singolo agente, ma
    possiamo estendere questa analisi a sistemi multi agente.
\end{nota}
\subsection{Tropistic Agents}
In questa classe gli agenti sono definiti attraverso una tupla composta da 6
elementi:
\begin{equation*}
    \langle E, P, A, \text{see}, \text{do}, \text{action} \rangle
\end{equation*}
dove:
\begin{itemize}
    \item $E$ è l'insieme degli stati dell'ambiente.
    \item $P$ è l'insieme delle percezioni, è una partizione di $E$.
    \item $A$ è l'insieme delle azioni.
    \item \textbf{see} è una funzione che mappa $E$ in $P$ e rappresenta quello
          che l'agente vede dell'ambiente.
    \item \textbf{action} è una funzione che mappa $P$ in $A$ è una funzione che
          seleziona l'azione che l'agente deve svolgere in base a una determinata
          percezione. È importante notare che abbiamo perso il fatto che il
          dominio non è l'insieme potenza delle percezioni.
    \item \textbf{do} è una funzione che mappa $A \times E$ in $E$ e rappresenta
          l'effetto di un'azione sull'ambiente.
\end{itemize}

In questa classe gli agenti osservano l'ambiente, scelgono l'azione appropriata
e la eseguono.
\subsection{Hysteretic Agents}
Gli agenti hysteretic sono definiti attraverso una tupla composta da 9 elementi:
\begin{equation*}
    \langle I, E, P, A, i_0, \text{see}, \text{internal,} \text{do}, \text{action} \rangle
\end{equation*}
dove:
\begin{itemize}
    \item $I$ è l'insieme degli stati interni.
    \item $E$ è l'insieme degli stati dell'ambiente.
    \item $P$ è l'insieme delle percezioni, è una partizione di $E$.
    \item $A$ è l'insieme delle azioni.
    \item $i_0$ è lo stato iniziale dell'agente.
    \item \textbf{see} è una funzione che mappa $E$ in $P$ e rappresenta quello
          che l'agente vede dell'ambiente.
    \item \textbf{internal} è una funzione che mappa $P \times I$ in $I$ e
          rappresenta l'effetto di una percezione sullo stato interno dell'agente.
    \item \textbf{do} è una funzione che mappa $A \times E$ in $E$ e rappresenta
          l'effetto di un'azione sull'ambiente.
    \item \textbf{action} è una funzione che mappa $P \times I$ in $A$ è una funzione
          che seleziona l'azione che l'agente deve svolgere in base a una determinata
          percezione e stato interno.
\end{itemize}
In questa classe gli agenti osservano l'ambiente, aggiornano il loro stato interno
e scelgono l'azione appropriata e la eseguono.
\subsection{Knowledge-based Agents}
Gli agenti knowledge-based sono definiti attraverso una tupla composta da 9 elementi:
\begin{equation*}
    \langle D, E, P, A, d_0, \text{see}, \text{database}, \text{do}, \text{action} \rangle
\end{equation*}
dove:
\begin{itemize}
    \item $D$ è l'insieme delle conoscenze dell'agente.
    \item $E$ è l'insieme degli stati dell'ambiente.
    \item $P$ è l'insieme delle percezioni, è una partizione di $E$.
    \item $A$ è l'insieme delle azioni.
    \item $d_0$ è lo stato iniziale del database dell'agente.
    \item \textbf{see} è una funzione che mappa $E$ in $P$ e rappresenta quello
          che l'agente vede dell'ambiente.
    \item \textbf{database} è una funzione che mappa $P \times D$ in $D$ e
          rappresenta l'effetto di una percezione sul database dell'agente.
    \item \textbf{do} è una funzione che mappa $A \times E$ in $E$ e rappresenta
          l'effetto di un'azione sull'ambiente.
    \item \textbf{action} è una funzione che mappa $P \times D$ in $A$ è una funzione
          che seleziona l'azione che l'agente deve svolgere in base a una determinata
          percezione e stato interno.
\end{itemize}
In questa classe gli agenti osservano l'ambiente, aggiornano il loro database
e scelgono l'azione da svolgere in in base a un ragionamento sulle conoscenze
possedute e infine eseguono l'azione.
\subsection{Russell e Norvig}
Una differente classificazione degli agenti è quella Russell e Norvig, la quale
classifica gli agenti in base alla loro architettura interna. Questa classificazione
distingue gli agenti in:
\begin{itemize}
    \item \textbf{Simple reflex agents}: selezionano l'azione in base alla percezione
          attuale, non mantiene lo storico delle percezioni. Sono agenti molto semplici
          che rispondono immediatamente a stimoli immediatamente percepiti dall'ambiente.
          \begin{figure}[!h]
              \centering
              \includegraphics[width=0.25\textwidth]{./img/Agenti/SimpleReflexAgents.png}
              \caption{Schema di un agente}
              \label{fig:simpleReflex}
          \end{figure}
    \item \textbf{Model-based reflex agents}: mantiene uno stato interno che permette
          di modellare lo storico delle percezioni che riceve dall'ambiente e sceglie
          l'azione in base al suo stato interno. Per aggiornare lo stato interno
          in base al cambiamento dell'ambiente ci servono 2 diverse conoscenze, ciascuna
          modellata da due diversi modelli:
          \begin{itemize}
              \item \textbf{transition model}: informazioni in merito
                    al cambiamento del mondo nel tempo, queste vengono raccolte dall'analisi
                    dell'effetto delle azioni dell'agente e dall'evoluzione dell'ambiente
                    indipendentemente dalle azioni dell'agente.
              \item \textbf{sensor model}: informazioni in merito
                    a come si riflette il cambiamento del mondo nelle percezioni dell'agente
          \end{itemize}
          L'insieme del transition e del sensor model permette all'agente di tenere
          traccia del mondo.
          \begin{figure}[!h]
              \centering
              \includegraphics[width=0.25\textwidth]{./img/Agenti/ModelBasedReflexAgent.png}
              \caption{Schema di un agente}
              \label{fig:ModelReflex}
          \end{figure}
    \item \textbf{Goal-based agents}: l'agente deve sapere quali sono le
          situazioni desiderate e quali azioni devono essere svolte per raggiungere
          tali situazioni. Ha sempre una rappresentazione del mondo derivante dal
          Model-based reflex agents, con la differenza che le decisioni prese sulla
          rappresentazione del mondo sono dipendenti dal Goal dell'agente.
          Risultano più flessibili rispetto ai Model-based reflex agent, dato che
          possono cambiare il comportamento solo cambiando il goal.
          \begin{figure}[!h]
              \centering
              \includegraphics[width=0.25\textwidth]{./img/Agenti/GlobalBasedAgent.png}
              \caption{Schema di un agente}
              \label{fig:GoalBased}
          \end{figure}
    \item \textbf{Utility-based agents}: in questo caso uno stesso obiettivo può
          essere raggiunto in modi diversi. Viene definita una funzione di utilità che
          che descrive il grado di soddisfazione dell'agente in base alla situazione
          in cui si trova. Ho bisogno
          di una funzione utilità che mi rappresenti il mondo in modo da guidare
          le scelte dell'agente in base alla rappresentazione e i suoi obiettivi.
          \begin{figure}[!h]
              \centering
              \includegraphics[width=0.25\textwidth]{./img/Agenti/UtilityBasedAgent.png}
              \caption{Schema di un agente}
              \label{fig:UtilityBased}
          \end{figure}
\end{itemize}

La prima classe di questa classificazione corrisponde alla classe degli agenti
tropistic, la seconda classe corrisponde alla classe degli agenti hysteretic. Le
altre due classi sono invece una specializzazione della classe knowledge-based.

Esistono altre classificazioni di agenti in base alle loro caratteristiche
fondamentali o in base alle capacità, un esempio sono gli agente di interfaccia.
Oltre a queste classificazioni possiamo distinguere agenti ibridi e sistemi
eterogenei.
\begin{esempio}[Esempio di agenti reattivi (Boids)]
    Agenti che simulano il comportamento di stormi di uccelli. Il comportamento
    è ottenuto mischiando i seguenti comportamenti:
    \begin{itemize}
        \item \textbf{Separazione}: ciascun Boids ha un raggio e riesce a percepire
              altri boids o ostacoli all'interno del raggio. Si ha un contributo
              nell'accelerazione verso la direzione opposta per evitare
              l'affollamento tra gli altri.
        \item \textbf{Coesione}: il Boids si muove verso la posizione centrale
              tra i vicini.
        \item \textbf{Allineamento}: orientamento spaziale deve conformarsi con
              i Boids adiacenti.
    \end{itemize}
    I comportamenti vengono uniti mediante una combinazione lineare e dei pesi.
\end{esempio}
Gli agenti reattivi non hanno obiettivi, si possono anche chiamare behaviour-based.
L'agente però è semplice computazionalmente, se voglio più complessità come per
esempio degli obiettivi allora devo complicare il modello.
\begin{esempio}[Esempio di agenti mentalistici (3APL)]
    L'agente prevede la specifica di un comportamento cognitivo mediante un
    linguaggio logico. Questo è caratterizzato da:
    \begin{itemize}
        \item Azioni base: singole azioni
        \item Belief base: insieme di fatti noti sul mondo, possono essere anche
              regole (base di conoscenza del mondo)
        \item Regole pratiche di ragionamento: insiemi di piani parzialmente istanziati,
              insieme di passi generiche che mi portano all'obiettivo
        \item Obiettivi
    \end{itemize}
    Esempio robot:
    \begin{itemize}
        \item Belief base: descrizione del mondo in PL.
        \item Capability: descrizione delle capacità (azione base) che può fare
              l'agente con la specifica di come deve essere aggiornata la base
              di conoscenza.
        \item Goal: obiettivo è la testa di una regola di un piano
        \item Rule base: insieme di piani, insieme di regole da mettere in pratica
              per portare a termine il piano e quindi l'obiettivo.
    \end{itemize}

    Hanno diversi problemi:
    \begin{itemize}
        \item Devono avere la rappresentazione completa del mondo (ambiente può
              essere molto grande)
        \item La percezione perde di significativo
        \item Come unisco reazione e deliberazione
    \end{itemize}
\end{esempio}
\begin{esempio} [Jade platform]
    Piattaforme SW per lo sviluppo di agenti, forniscono solo uno "standard SW"
    per eseguire comportamenti. L'agente viene eseguito dall'ambiente che sveglia
    chi deve eseguire e non vengono eseguiti su Thread. Quindi
\end{esempio}

Gli agenti come mostra Jade possono essere a oggetti, ma ci possono essere differenze:
\begin{itemize}
    \item \textbf{Autonomia}: un agente può fornire servizi ma non devono
          rispondere a tutte le richieste.
    \item \textbf{Pro-attività}: un agente deve avere almeno un thread per il
          suo controllo, gli oggetti in Jade non vengono eseguiti su thread.
    \item \textbf{Abilità sociale}: per gli oggetti non si hanno comunicazione
          sociale perché è limitata alla sua interfaccia che non è abbastanza
          espressiva rispetto ad un modello sociale di comunicazione.
\end{itemize}
Gli agenti possono essere visti come una specializzazione degli oggetti comuni.
\subsection{Agenti ibridi}
Gli agenti ibridi sono una tipologia di agenti intelligenti aventi una struttura
composta da strati. Ogni strato implementa un comportamento specifico.
L'architettura può essere espressa come specifiche comportamentali a layer che
può essere:
\begin{itemize}
    \item Orizzontale: una singola percezione può portare all'attivazione di due
          comportamenti paralleli.
    \item Verticale: si ha una gerarchia con priorità sui comportamenti più
          importanti.
\end{itemize}
% ! Immagine di un agente ibrido
\subsection{Sistema eterogeneo}
Un sistema complesso può integrare quindi diverse tipologie di agenti
(sistema eterogeneo), diventa fondamentale la loro interazione, specificando dei
meccanismi di interazione (ex: robot spaziali).

L'autonomia degli agenti può avere diverse declinazioni:
\begin{itemize}
    \item Capacità di un agente di decidere le proprie azioni in base allo stimolo
          esterno.
    \item Abilità di decidere in base alla sua conoscenza.
\end{itemize}
\subsection{Learning agent}
I learning agent sono agenti che integrano un processo di apprendimento. Nello
specifico contengono:
\begin{itemize}
    \item \textbf{Learning element}: l'agente apprende e modifica il suo comportamento
          in base alle percezioni. Contiene l'algoritmo di apprendimento.
    \item \textbf{Performance element}: l'agente sceglie le azioni in base alle
          percezioni. Contiene il modello appreso.
\end{itemize}
% ! Immagine di un learning agent

Se l'agente contiene un learning element allora può apprendere durante la sua vita,
altrimenti l'apprendimento può essere fatto a priori e quindi l'agente è solo il
risultato del processo. Nel caso in cui il learning element non sia presente
l'agente non è definito come learning agent.

Spesso questi agenti vengono allenati utilizzando tecniche di reinforcement
learning, ovvero gli agenti compiono delle azioni e come risposta all'azione
ottengono un punteggio che li premia o penalizza. In questo modo l'agente esplora
l'effetto delle azioni nell'immediato o nel lungo termine.

\section{Agent interaction}
Vogliamo ora studiare come gli agenti interagiscono con altri agenti e/o con
l'ambiente. Iniziamo definendo cosa si intende per \textbf{interazione}.
\begin{definizione}[\textbf{Interazione}]
    Un'interazione occorre quando 2 o più agenti hanno una relazione dinamica
    attraverso delle azioni reciproche. Un esempio di interazione è rappresentata
    da un agente che richiede delle informazioni e uno che le fornisce quando
    riceve la richiesta.
\end{definizione}
L'interazione è necessaria quando un singolo agente non può svolgere il compito
ad esso associato, questo spesso è dovuto per le seguenti motivazioni:
\begin{itemize}
    \item Risorse insufficienti (non conosco l'informazioni)
    \item Risorse che possono essere intrinsecamente distribuite nell'ambiente
          (non possono accedere all'informazioni)
    \item Abilità insufficienti (non posso trasportare dei materiali)
    \item Usare un approccio distribuito per risolvere un particolare problema
\end{itemize}

Le interazioni possono essere classificate in base a diversi criteri. Un primo
criterio di classificazione si basa sulla compatibilità degli obiettivi,
disponibilità delle risorse e abilità degli agenti. Questo non è l'unico criterio
di classificazione per le interazioni.

Risulta interessante lo studio di come far interagire gli agenti al netto della
loro architettura interna. Nel nostro caso ci concentreremo sulla loro
comunicazione, studieremo dei \textbf{modelli di interazione}.

% TODO: aggiungi schema di interazione
\subsection{Interazione diretta}
Gli agenti sono in grado di scambiare informazioni direttamente. Lo scambio di
informazioni avviene attraverso:
\begin{itemize}
    \item \textbf{Communication/Conversation rules}: vengono definite delle
          regole per gestire le conversazioni, queste regole prendono il nome di
          Agent Communication Language (ACL).
    \item \textbf{Message structure and contents}: specifica effettivamente il
          linguaggio per esprimere il contenuto, bisognerà quindi specificare
          delle ontologie condivise.
\end{itemize}

In questa tipologia di comunicazione i messaggi non si devono deteriorare, ovvero
il messaggio non viene alterato nel mentre, quindi lo scambio di messaggi viene
definito \textbf{indiscriminato}. È molto importante, per questo tipo di
comunicazione, che gli agenti conoscano per poter interagire.
\begin{esempio}[\textbf{KQML}]
    Un esempio di modello per la comunicazione diretta sono \textbf{KQML} e
    \textbf{KIF}, i quali sono stati prodotti da ARPA knowledge sharing effort.
    Nello specifico:
    \begin{itemize}
        \item \textbf{KQML}: Knowledge Query and Manipulation Language, è un
              linguaggio per la comunicazione tra agenti. È un linguaggio ad
              alto livello.
        \item \textbf{KIF}: Knowledge Interchange Format, è un linguaggio per
              rappresentare il contenuto.
    \end{itemize}

    KQML definisce delle primitive per comporre una conversazione tra agenti.
    L'idea su cui si basa è quella dell'atto comunicativo, ovvero su un'etichetta
    che dice all'interlocutore come interagire in una comunicazione.

    Un messaggio KQLM ha una sintassi simile a lisp composto da:
    \begin{itemize}
        \item Performative: azione o scopo del messaggio, sono diverse tra query,
              informazioni, richieste, risposte\dots
        \item Parametri: parametri informativi come ontologie in comune.
        \item Valore:
    \end{itemize}
    Il messaggio specifica un singolo atto comunicativo che fa parte di una comunicazione.
\end{esempio}

Come già anticipato, gli agenti devono conoscere il loro partner di comunicazione,
per fare ciò possiamo assegnare un nome agli agenti, inoltre per aiutare gli
agenti a capire chi è l'agente con il quale si vuole comunicare si possono
utilizzare dei facilitatori, ovvero degli intermediari che aiutano gli agenti
a trovare il partner di comunicazione. Questi agenti si occupano di creare un
registry dei nomi, come ad esempio fa il DNS nelle reti. In aggiunta essendo in
un mondo distribuito dobbiamo anche avere robustezza, quindi repliche e studio
su come mantenerli allineati.

Oltre a questo, bisogna anche definire una semantica per la comunicazione, si
possono specificare dei ragionatori logici, il problema di questa soluzione è
che si va a perdere l'autonomia degli agenti.

La specifica della conversazione può essere espressa tramite automi a stati finiti
o reti di petri, in questo modo si limita l'autonomia.

I protocolli di interazione diretta sono simili ai protocolli per sistemi distribuiti,
si hanno scambi di messaggi punto-punto e sono facilmente implementabili sopra
un middleware. Il problema è che si hanno problemi di definizioni di ontologie
comuni, ci sono problemi sulla semantica perché si perde autonomia e si ha un
problema di discovery.

Per la gestione della comunicazione diretta si possono avere registry multipli
per garantire la robustezza, inoltre si possono informare anche gli agenti sulle
capacità degli altri.

Possiamo avere anche robe più complicate rispetto ai registry, per esempio i broker.
Si ha quindi scambi di messaggi con un meccanismo di publish and subscribe tra
i singoli agenti. Ogni agente si iscrive alla lista di messaggi se vuole accedere
alla comunicazione con un sottoinsieme di agenti. Questa metodologia risolve il
problema dei naming e non mette in comunicazione direttamente due agenti,
ovviamente i messaggi sono accessibili solo se gli agenti sono attivi al momento
dell'invio.
\subsection{Interazione indiretta}
In questa tipologia di comunicazione tra gli agenti è presente un intermediario,
il quale non è un agente ma un'entità che si occupa di gestire la comunicazione
tra gli agenti. Questa entità fornisce i meccanismi di interazione e
definisce le regole di interazione tra gli agenti. Questi definiscono un
contesto locale e delle percezioni. Sono presenti dei disaccoppiamenti
dei nomi e non tutti gli agenti devono essere online nel sistema, si ha quindi
anche un disaccoppiamento nel tempo. Infine si ha disaccoppiamento spaziale
perché possono pubblicare i messaggi e disattivarsi.
\subsubsection{Guidata da artefatti}
L'interazione può essere mediata attraverso artefatti condivisi, i quali possono
essere:
\begin{itemize}
    \item Osservati
    \item Modificati
\end{itemize}
Questi elementi costituiscono un canale di comunicazione tra gli agenti, che
viene caratterizzato da una trasmissione broadcast. Gli agenti che vogliono
accedere a questo canale possono farlo attraverso delle regole di accesso.

La comunicazione può avvenire secondo il \textit{sistema blackboard} con
controllo degli accessi. Si ha un qualcosa che tutti gli agenti possono vedere
contemporaneamente, mentre per scrivere si utilizza un controllo degli accessi.

Un implementazione di questo meccanismo è Linda, la quale struttura i dati che
contiene come delle tuple ognuna delle quali contiene informazioni, una diversa
tipologia di tuple sono quelle che contengono i processi.

A questo punto i processi possono leggere e scrivere le tuple che si hanno in
condivisione. Gli agenti possono anche comunicare leggendo tuple, scrivendo tuple,
consumando tuple e creando processi di calcolo.

Il problema di questo metodo è che se ci troviamo in un mondo distribuito,
dobbiamo analizzare come gestire lo spazio di tuple condiviso. Una soluzione
consiste nel salvare tale spazio in diversi nodi e implementare un middleware che
si occupa di aggiornare esso. Lo spazio distribuito può essere programmato o reattivo,
si possono aggiungere anche astrazioni come regole o policies del mondo.

Come si può capire, il problema di questo metodo è dato dalla difficoltà di
implementazione del meccanismo.

riassumendo:
\begin{itemize}
    \item \textbf{Interazione diretta}: percezioni e azioni devono essere passati
          per messaggi.
    \item \textbf{Interazione indiretta con artefatti}:  non tutto deve essere
          un messaggio, l'artefatto è l'ambiente e le letture e scritture di tuple
          è la comunicazione. L'ambiente viene rappresentato dalle tuple.
\end{itemize}
\subsubsection{Basata sull'ambiente}
L'interazione può essere mediata attraverso una struttura spaziale che
rappresenta esplicitamente l'ambiente, la rappresentazione deve essere algebrica
e spaziale. Un esempio sono gli automi cellulari, i quali possono essere
classificati come agenti Hysteretic.
\section{Ambiente}
L'ambiente può essere visto come il contesto nel quale gli agenti agiscono. Per
esso si possono definire diverse caratteristiche:
\begin{itemize}
    \item \textbf{Accessibile}: l'agente può ottenere informazioni complete,
          aggiornate e accurate sullo stato dell'ambiente. In caso di assenza di
          alcune di queste caratteristiche si parla di \textbf{parzialmente
              accessibile} o \textbf{non accessibile}.
          Non sempre si possono avere informazioni complete come nel poker.
          Non sempre tutte le informazioni si possono avere accurate, ex: area
          B te puoi anche non uscire. Non sempre possiamo avere un'informazione
          aggiornata perché dipende dalle frequenze di campionamento dei sensori.

          Più è accessibile l'ambiente allora più è facile operare in esso.
    \item \textbf{Deterministico}: l'agente quando decide l'effetto dell'azione
          deve essere certo. In un ambiente \textbf{non deterministico}
          l'agente deve controllare l'effetto delle sue azioni.
    \item \textbf{Static}: l'ambiente è statico se non cambia mentre
          l'agente decide. Al contrario si tratta un ambiente \textbf{Dynamic}.
    \item \textbf{Discreto}: se ci sono un numero fisso di azioni e percezioni
          possibili. Al contrario si tratta di un ambiente \textbf{Continuo}.
\end{itemize}

Il comportamento degli agenti può essere influenzato dall'ambiente. Gli agenti
semplici sono quelli che si comportano in modo reattivo rispetto all'ambiente.
Mentre gli agenti più complessi o pro-attivi allora l'ambiente è un fornitore di
informazioni o un vincolo sul proprio piano.

L'ambiente contiene gli agenti, i quali hanno specifiche comportamentali
differenti, l'interazione può avvenire in forma diretta o mediata, l'ambiente
gestisce la dinamica complessiva (gestisce il tempo), inoltre può essere da
tramite per la comunicazione diretta tra agenti.

In base a come si vuole modellare l'ambiente può essere utile specificare delle
regole. Ad esempio, se vogliamo descrivere un mondo reale si possono specificare
le regole fisiche.

\begin{table}[!ht]
    \centering
    \begin{tabular}{@{}lccc@{}}
        \toprule
        \rowcolor[HTML]{EFEFEF}
                                                                                                                             &
        \multicolumn{1}{l}{\cellcolor[HTML]{EFEFEF}Direct Interaction}                                                       &
        \multicolumn{1}{l}{\cellcolor[HTML]{EFEFEF}\begin{tabular}[c]{@{}l@{}}Indirect Artifact \\ Based\end{tabular}}       &
        \multicolumn{1}{l}{\cellcolor[HTML]{EFEFEF}\begin{tabular}[c]{@{}l@{}}Indirect Spatially \\ founded\end{tabular}}                     \\ \midrule
        \begin{tabular}[c]{@{}l@{}}Time/Space\\ uncoupling\end{tabular}                                                      & No & Yes & Yes \\
        Name uncoupling                                                                                                      & No & Yes & Yes \\
        Agent Environment                                                                                                    &
        \begin{tabular}[c]{@{}c@{}}Communication\\ infrastructure\end{tabular}                                               &
        Shared Artifact                                                                                                      &
        \begin{tabular}[c]{@{}c@{}}Spatial representation \\ of agents' environment \\ and its properties\end{tabular}                        \\
        Agent context                                                                                                        &
        \begin{tabular}[c]{@{}c@{}}Well known middle-\\ agents, other known \\ agents and its \\ knowledge base\end{tabular} &
        \begin{tabular}[c]{@{}c@{}}Information present in \\ the artifact and its state\end{tabular}                         &
        \begin{tabular}[c]{@{}c@{}}Viewable portion of \\ space and its state\end{tabular}                                                    \\ \bottomrule
    \end{tabular}
\end{table}

In caso di interazione diretta l'ambiente fa da registri o middle agent.