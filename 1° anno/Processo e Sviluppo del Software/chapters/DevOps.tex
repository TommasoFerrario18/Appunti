\chapter{DevOps}
Negli ultimi tempi si è sviluppato un altro metodo, chiamato DevOps, dove anche
la parte di \textbf{operation} deve essere agile: il rilascio in produzione e il
deployment devono essere agili quanto lo
sviluppo.

Nel DevOps (\ref{fig:devops}) i team di sviluppo e operation sono indipendenti
tra loro, diminuendo il costo di impegno necessario al team di sviluppo per la parte
di deployment, la quale viene resa anche più sicura grazie alla diminuzione
dell'intervento umano in favore di automazioni. Inoltre, avendo i due team dei
tempi di lavoro diversi, si riesce a prevenire ritardi causati dalla non
organicità delle operazioni.

\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.5]{img/devops/devops.png}
    \caption{Rappresentazione del lifecycle di DevOps}
    \label{fig:devops}
\end{figure}

DevOps promuove la collaborazione tra di due team al fine di ottenere una sorta
di team unico che curi sia sviluppo che operation. DevOps include quindi diversi
processi che vengono automatizzati:
\begin{itemize}
    \item Continuous Development
    \item Continuous Integration
    \item Continuous Testing
    \item Continuous Deployment
    \item Continuous Monitoring
\end{itemize}

Con DevOps il feedback arriva in primis dal software inoltre il focus viene
spostato sui processi automatici. Nel DevOps si introducono nuovi ruoli:
\begin{itemize}
    \item Il \textbf{DevOps Evangelist}, simile allo scrum master, supervisiona
          l'intero processo di DevOps.
    \item L'\textbf{automation expert}, dedicato a curare gli aspetti di automatismo.
    \item Un \textbf{Security Engineer}
    \item Un \textbf{Software Developer}, nonché Tester
    \item Un \textbf{Quality Assurance} che verifica la qualità del prodotto
          rispetto ai requisiti.
    \item Un\textbf{ Code Release Manager} che si occupa sull'infrastruttura e
          sul deploy della release
\end{itemize}

DevOps si basa su sei principi base:
\begin{enumerate}
    \item \textbf{Customer-Centric Action}, ovvero il committente è al centro
          dell'azione
    \item \textbf{End-To-End Responsibility}, ovvero il team gestisce interamente
          il prodotto, avendone responsabilità totale
    \item \textbf{Continuous Improvement}, ovvero cercare continuamente di
          migliorare senza sprechi il prodotto finale e i servizi.
    \item \textbf{Automate everything}, ovvero cercare di automatizzare l'intera
          nfrastruttura di processo, dalle attività di testing e integrazione fino ad
          arrivare alla costruzione della release e del deployment.
    \item \textbf{Work as one team}, ovvero unificare tutti gli aspetti sotto un
          unico team o comunque con due team che collaborano fortemente come se fossero uno.
    \item \textbf{Monitor and test everything}, ovvero testare e monitorare
          costantemente il prodotto
\end{enumerate}

Il quarto e il sesto punto sono i due punti tecnici principali.
\section{Build, Test e Release}
Bisogna pensare a questi step in ottica di automatismo vicina al DevOps.
Innanzitutto bisogna introdurre i sistemi di version control (Git) un sistema di
version control distribuito, dove ogni utente ha una copia della repository
(con la storia dei cambiamenti), con la quale interagisce tramite commit e update.
Esiste poi una repository lato server per permettere di condividere i vari
cambiamenti tramite sincronizzazione.

\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.5]{img/devops/git.png}
    \caption{Struttura ideale di un repository git}
    \label{fig:git}
\end{figure}

Lo sviluppo su multi-branch si collega alle operazioni di verifica che possono
essere attivate automaticamente a seconda dell'evoluzione del codice su ogni branch.
Avendo ogni branch una precisa semantica possiamo definire precise attività di
verifica, corrispondenti a pipelines precise, solitamente innescate da un push di
codice su un certo branch, in modo sia automatico che manuale.
Le pipeline vengono attivate in fase di test di un componente, in fase di creazione
di un sottosistema, di assembramento di un sistema intero o di deployment in
produzione. Si hanno quindi quattro fasi:
\begin{enumerate}
    \item \textbf{component phase}
    \item \textbf{subsystem phase}
    \item \textbf{system phase}
    \item \textbf{production phase}
\end{enumerate}

Spesso le pipelines sono usate come \textbf{quality gates} per valutare se un push
può essere accettato in un certo branch. Una pipeline può essere anche regolata
temporalmente, in modo che avvenga solo ad un certo momento della giornata.
\subsection{Component phase e Subsystem phase}
Dove il fuoco è sulla più piccola unità testabile che viene aggiornata che non
può essere eseguita senza l'intero sistema. In tal caso si può fare:
\begin{itemize}
    \item Code review
    \item Unit testing
    \item Static code analysis
\end{itemize}

Un cambiamento può anche essere testato nell'ambito del sottosistema di cui fa
parte, in tal caso si hanno anche check di prestazioni e sicurezza. Il servizio
però potrebbe essere da testare in isolamento rispetto ad altri servizi, usando quindi
dei mocks o degli stubs, ovvero creando degli alter ego dei servizi mancanti in
modo che il servizio da testare possa funzionare.
\subsection{System phase}
In questo caso si testa l'intero sistema che viene “deployato” in ambiente di test.
Si hanno:
\begin{itemize}
    \item Integration tests
    \item Performance tests
    \item Security tests
\end{itemize}

Tutti test che richiedono l'interezza del sistema e sono spesso molto dispendiosi e
quindi bisogna regolare la frequenza di tali test in molti casi.
\subsection{Production phase}
Questa fase è legata alla necessità di creare gli artefatti che andranno
direttamente “sul campo”, ovvero il deployment in produzione. In tale fase potrebbe
essere necessario creare container o macchine virtuali. Si hanno dei check molto
veloci sugli artefatti finali, dando per assodato che la qualità del codice sia già
stata testata. Si hanno quindi strategie anche di deployment incrementale, per
cui esistono più versioni del software contemporaneamente con diversa accessibilità
per gli utenti finali. In tal caso si usano anche vari tool di monitor. Si hanno
anche eventualmente tecniche di zero downtime.

Fasi diverse corrispondono a branch diversi
\section{Deploy, Operate e Monitor}
Si studia l'evoluzione automatica del software da una versione all'altra in
produzione. Avanzare di versione in modo naive e istantaneo è troppo rischioso e
quindi spesso non attuabile. Si ha quindi un insieme di tecniche che si basano
in primis sull'evoluzione incrementale.

Tali tecniche si distinguono in base alla dimensione su cui sono incrementati:
\begin{itemize}
    \item \textbf{Incremental with reference to users}: Dark launching, Canary
          releases (and User Experimentation), ovvero legata agli utenti esposti alla nuova release.
    \item \textbf{Incremental with reference to requests}: Gradual upgrades/rollout,
          ovvero legata alle richieste per la nuova release.
    \item \textbf{Incremental with reference to components/replicas}: Rolling upgrade,
          incentrata sulle componenti che vengono aggiornate.
    \item \textbf{Non-incremental with backups}: Green/blue deployment,
          Rainbow deployment, non incrementali ma che offrono comunque un backup di sicurezza.
\end{itemize}

Tali schemi possono essere usati in un contesto DevOps. Per studiare la prima
tipologia (Incremental with reference to users) abbiamo:
\begin{itemize}
    \item \textbf{Dark launching}: In tale schema l'update è esposto solo ad una
          parte della popolazione, per la quale viene effettuato il deployment per
          studiare gli effetti ed eventuali modifiche e migliorie al software, che infine
          verrà deployato per il resto della popolazione in modo comunque incrementale
          fino a che l'intera popolazione godrà della feature.
    \item \textbf{Canary releases}, che studia l'impatto di update relativi al
          backend
\end{itemize}

Tali schemi spesso sono usati di pari passo per le varie sezioni del software,
nonché possono essere usati in modo intercambiabile.

Collegato a questi schemi si ha l'approccio basato sull'\textbf{user experimentation},
che non è un reale schema di gestione dell'evoluzione del software ma è comunque correlato
agli schemi sopra descritti. In questo approccio si studiano diverse varianti del
sistema e il loro impatto esponendole agli utenti, cercando di capire per l'utente
cosa sia meglio e come. Si hanno quindi più release diverse, per parti di
popolazione comparabili, tra le quali si sceglierà la migliore.

Per la seconda tipologia (Incremental with reference to requests) si ha una
divisione a seconda delle richieste fatte dagli utenti, detto \textbf{gradual rollout}.
Si ha quindi un load balancer che permette la coesistenza di due versioni, una
nuova e una vecchia, dello stesso servizio. In modo graduale, partendo da pochissime,
si passano le richieste alla versione nuova per poter studiare e testare la nuova
versione. Alla fine tutto il traffico sarà diretto verso la nuova versione, mentre
la vecchia verrà dismessa.

Per la terza tipologia (Incremental with reference to components/replicas),
si ha lo schema del \textbf{rolling upgrade}, dove l'upgrade non riguarda un
singolo upgrade ma tanti componenti di un sistema distribuito, verificando efficacia
di ogni singolo update tramite il continuous monitoring prima di effettuare l'upgrade
di un'altra componente. La stessa idea su applica anche a diverse versioni dello
stesso prodotto, aggiornandone una prima e poi le altre progressivamente.

Per la quarta tipologia (Non-incremental with backups) si ha il
\textbf{blue/green deployment}, dove vengono isolate due copie della stessa
infrastruttura, dove una ospita la versione nuove l'altra la vecchia. Un router
ridireziona le richieste degli utenti verso le due unità e quella che ospita la
nuova versione subirà le solite operazioni di test che, se superate, porteranno
il router a direzionare verso quella unità, ignorando la vecchia. Se ci sono problemi
si fa rollback alla vecchia unità che rimane come backup. Questo schema può essere
generalizzato nel rainbow deployment dove il momento di coesistenza tra le due
versioni viene prolungato al fine che vecchie richieste che richiedono una lunga
elaborazione vengano elaborate dall'unità vecchia mentre le nuove dall'unità nuova.

In ogni caso le applicazioni devono essere costruite per supportare tutti questi
schemi di deployment.
\subsection{Deployable units}
Il caso più tipico in merito alle unità dove fare deployment è il mondo del cloud,
con unità virtualizzate e virtual machine (VM), dove magari ogni servizio vive in
una diversa VM. Si hanno diversi casi in merito a questo tipo di deployment:
\begin{itemize}
    \item \textbf{Cloud basato su VMs}, dove si ha un'infrastruttura gestita dal
          cloud provider che gestisce l'hardware e l'hypervisor. Ogni VM, che sono le
          nostre unità di deployment, ha un sistema operativo arbitrario che lavora con
          l'hardware mostrato dall'hypervisor. Ogni VM avrà una o più applicazioni e
          fare deployment porterà all'update di una o più VM. In alcuni casi si fa
          deployment di intere VM e in altri si modifica il software di una VM già
          in esecuzione. L'ambiente cloud solitamente è multi-tenant, ovvero su una
          piattaforma unica di un provider si hanno più VM di diverse organizzazioni.
          Una VM è grossa in quanto contiene un sistema operativo intero e la loro
          gestione può quindi essere difficoltosa.
    \item \textbf{Cloud basato su containers} che risolvono il problema della
          grandezza delle VM. In questo caso lo schema è il medesimo ma si ha un container
          engine al posto dell'hypervisor e ogni container non contiene l'intero sistema
          operativo ma solo il minimo necessario al funzionamento dell'applicazione. In
          questo caso lo schema di update spesso consiste nel distruggere e ricreare
          i singoli containers. Anche qui si ha un contesto multi-tenant.
    \item \textbf{Bare metal}, dove i provider offrono direttamente risorse
          hardware, guadagnando prestazioni ma aumentano anche i costi economici ,
          che vengono comunque gestite dal cloud provider. Non si ha virtualizzazione
          ma accesso diretto alle risorse su cui fare deployment. Questa è una soluzione
          tipicamente single-tenant.
    \item \textbf{Server dedicati}, un metodo ormai superato con difficoltà causate
          dall'uso di script, shell e connessione ftp completamente autogestiti
          dall'organizzazione e non da un provider.
\end{itemize}

Il deployment “stile cloud” non è comunque l'unico possibile.
\subsection{Monitor}
In ambiente cloud ci sono tante soluzioni per il monitoring, ad esempio lo stack
di ELK, formato da:
\begin{itemize}
    \item Elasticsearch
    \item Logstash
    \item Kibana
\end{itemize}

I dati, ad esempio log o metriche d'uso hardware, vengono raccolti e passano da
Logstash, finendo in un database, per la memorizzazione di time series (serie temporali)
di dati (questo in primis per le metriche d'uso che per i log), gestito da Elasticsearch
e venendo visualizzati da una dashboard grafica, gestita da Kibana. Si ha quindi
un ambiente di continuous monitoring.
\subsection{DevOps tools}
Ogni step del DevOps è gestito tramite moderne tecnologie e tools , con varie
alternative per ogni fase (per questo servono figure esperte per ogni step).
